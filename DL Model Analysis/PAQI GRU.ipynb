{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S8qe-K-Bcyg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# ---------------------- 1. DATA PREPROCESSING ---------------------- #\n",
        "class AQIDataset(Dataset):\n",
        "    def __init__(self, data, seq_length):\n",
        "        self.data = data\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(self.data[idx:idx+self.seq_length], dtype=torch.float32),\n",
        "            torch.tensor(self.data[idx+self.seq_length], dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "def load_and_preprocess_data(file_path, seq_length=20, train_split=0.8):\n",
        "    df = pd.read_csv(file_path, parse_dates=['From Date'], index_col='From Date')\n",
        "    df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_data = scaler.fit_transform(df[['Overall AQI']].values)\n",
        "\n",
        "    train_size = int(len(normalized_data) * train_split)\n",
        "    train_data, test_data = normalized_data[:train_size], normalized_data[train_size:]\n",
        "\n",
        "    train_dataset = AQIDataset(train_data, seq_length)\n",
        "    test_dataset = AQIDataset(test_data, seq_length)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, scaler\n",
        "\n",
        "# ---------------------- 2. GRU MODEL ---------------------- #\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, dropout=0.2):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.batch_norm(out[:, -1, :])\n",
        "        return self.fc(out)\n",
        "\n",
        "# ---------------------- 3. TRAINING FUNCTION ---------------------- #\n",
        "def train_model(model, train_loader, test_loader, num_epochs=100, lr=0.001, patience=10):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_batch)\n",
        "            loss = criterion(y_pred.squeeze(), y_batch.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in test_loader:\n",
        "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "                y_pred = model(x_batch)\n",
        "                loss = criterion(y_pred.squeeze(), y_batch)\n",
        "                test_loss += loss.item()\n",
        "        test_loss /= len(test_loader)\n",
        "        scheduler.step(test_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.5f}, Test Loss={test_loss:.5f}\")\n",
        "\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ---------------------- 4. EVALUATION FUNCTION ---------------------- #\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "    model.eval()\n",
        "    actuals, predictions = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in test_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(x_batch).squeeze()\n",
        "            actuals.extend(y_batch.tolist())\n",
        "            predictions.extend(y_pred.tolist())\n",
        "\n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "    mse = mean_squared_error(actuals, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(actuals, predictions)\n",
        "    mape = np.mean(np.abs((np.array(actuals) - np.array(predictions)) / np.array(actuals))) * 100\n",
        "\n",
        "    print(f\"Evaluation Metrics: MAE={mae:.4f}, MSE={mse:.4f}, RMSE={rmse:.4f}, RÂ²={r2:.4f}, MAPE={mape:.4f}%\")\n",
        "    return actuals, predictions\n",
        "\n",
        "# ---------------------- 5. VISUALIZATION FUNCTION ---------------------- #\n",
        "def plot_predictions(actuals, predictions):\n",
        "    actuals = np.array(actuals).flatten()\n",
        "    predictions = np.array(predictions).flatten()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(actuals, label=\"Actual AQI\", color='blue')\n",
        "    plt.plot(predictions, label=\"Predicted AQI\", linestyle='dashed', color='red')\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.ylabel(\"AQI\")\n",
        "    plt.title(\"Actual vs Predicted AQI\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(actuals, predictions, alpha=0.7, edgecolors='k', label=\"Predicted vs Actual\")\n",
        "    plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], color=\"red\", linestyle='--', label=\"Perfect Prediction\")\n",
        "    plt.xlabel(\"Actual AQI\")\n",
        "    plt.ylabel(\"Predicted AQI\")\n",
        "    plt.title(\"Scatter Plot: Actual vs Predicted AQI\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------- 6. MAIN FUNCTION ---------------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"KNN_IMPUTED_HYD_AQI_TIME_SERIES_SORTED_with_AQI_NORMALIZED_data.csv\"\n",
        "    seq_length = 20\n",
        "    train_loader, test_loader, scaler = load_and_preprocess_data(file_path, seq_length)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GRUModel().to(device)\n",
        "    train_model(model, train_loader, test_loader)\n",
        "    actuals, predictions = evaluate_model(model, test_loader)\n",
        "    plot_predictions(actuals, predictions)\n"
      ]
    }
  ]
}